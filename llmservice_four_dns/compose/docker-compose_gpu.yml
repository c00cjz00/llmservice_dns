version: "3.9"

name: nchcsystem

networks:
  nchc:
    external: false
    
services:

  nchc_juicer:
    container_name: nchc_juicer
    image: datajuicer/data-juicer:v0.2.0
    ports:
      - ${nchc_juicer}:8501
    volumes:
      - ./juicer:/data-juicer
      - ./storage/juicer_cache:/root/.cache
    restart: unless-stopped
    networks:
      - nchc     
    working_dir: /data-juicer 
    command: bash -c "sleep infinity"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]
              
  nchc_factory:
    container_name: nchc_factory
    image: c00cjz00/factory:latest
    ports:
      - ${nchc_factory}:7860
      - ${nchc_factory_notebook}:9999
    volumes:
      - ./storage:/storage    
      - ./storage/output:/output    
      - ./storage/jupyter_data:/workspace    
      - ./storage/hf_cache:/root/.cache/huggingface
      - ./storage/factory_data:/app/data
      - ./storage/factory_saves:/app/saves
      - ./storage/factory_cache:/app/cache
      - ./factory/src/webui.py:/app/src/webui.py
      - ./factory/src/llamafactory/webui/interface.py:/app/src/llamafactory/webui/interface.py
      - ./factory/src/llamafactory/webui/locales.py:/app/src/llamafactory/webui/locales.py
      - ./factory/src/llamafactory/data/template.py:/app/src/llamafactory/data/template.py
    environment:
      - TZ=Asia/Taipei
      - HF_TOKEN=${HF_TOKEN}
      - GRADIO_USER=${SYSTEM_USER}
      - GRADIO_PASSWORD=${SYSTEM_KEY}
    restart: unless-stopped
    networks:
      - nchc
    extra_hosts:
      - host.docker.internal:host-gateway      
    working_dir: /workspace
    command: bash -c "cd /app && llamafactory-cli webui > /workspace/factory.log 2>&1 & jupyter lab --NotebookApp.token=${SYSTEM_KEY} --notebook-dir=/workspace --port=9999"      
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]
 
  nchc_mergekit:
    container_name: nchc_mergekit
    image: registry.hf.space/arcee-ai-mergekit-gui
    pull_policy: always
    ports:
      - ${nchc_mergekit}:8860
    volumes:
      - ./storage/mergekit_tmp:/tmp
      - ./mergekit/app.py:/home/user/app/app.py
      - ./mergekit/examples:/home/user/app/examples
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - GRADIO_USER=${SYSTEM_USER}
      - GRADIO_PASSWORD=${SYSTEM_KEY}
      - GRADIO_SERVER_PORT=8860
      #- GRADIO_SERVER_NAME=
      #- GRADIO_ROOT_PATH=
    restart: unless-stopped
    networks:
      - nchc 
    command: python app.py
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]
              
  nchc_ollama:
    container_name: nchc_ollama
    image: ollama/ollama:latest
    pull_policy: always
    ports:
      - ${nchc_ollama}:11434    
    volumes:
      - ./storage/ollama_data:/root/.ollama
      - ./storage/output:/output          
    tty: true
    restart: unless-stopped
    networks:
      - nchc
    deploy:
      resources:
        #limits:
        #  cpus: '4.50'
        #  memory: 5000M       
        reservations:
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]
              
  nchc_openwebui:
    container_name: nchc_openwebui
    image: ghcr.io/open-webui/open-webui:main
    pull_policy: always
    ports:
      - ${nchc_openwebui}:8080
    volumes:
      - ./storage/openwebui_data:/app/backend/data
    restart: unless-stopped
    networks:
      - nchc
    depends_on:
      - nchc_ollama      
    environment:
      - '/ollama/api=http://nchc_ollama:11434/api'
      - 'OLLAMA_BASE_URL=${OLLAMA_BASE_URL}'
      - 'OPENAI_API_BASE_URLS=${OPENAI_API_BASE_URLS}'
      - 'OPENAI_API_KEYS=${OPENAI_API_KEYS}'      
    extra_hosts:
      - host.docker.internal:host-gateway
              
  nchc_anythingllm:
    container_name: nchc_anythingllm
    image: mintplexlabs/anythingllm
    pull_policy: always
    ports:
      - ${nchc_anythingllm}:3001    
    volumes:
      - ./storage/anythingllm_data:/app/server/storage
      - ./storage/anythingllm_hotdir:/app/collector/hotdir
      - ./storage/anythingllm_outputs:/app/collector/outputs
      - ./storage/anythingllm_env.txt:/app/server/.env
    cap_add:
      - SYS_ADMIN
    user: "${UID:-1000}:${GID:-1000}"
    env_file:
      - .env	  
    networks:
      - nchc    
    extra_hosts:
      - host.docker.internal:host-gateway   
    environment:
      - STORAGE_DIR=/app/server/storage
      - SERVER_PORT=3001
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: "all"
              capabilities: [gpu]

  nchc_litellm:
    container_name: nchc_litellm
    image: ghcr.io/berriai/litellm:main-latest
    pull_policy: always    
    ports:
      - ${nchc_litellm}:4000
    volumes:
      - ./litellm/litellm-config.yaml:/app/config.yaml 
    restart: unless-stopped
    networks:
      - nchc
    depends_on:
      - nchc_postgres
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@host.docker.internal:5432/${POSTGRES_DB}
    extra_hosts:
      - host.docker.internal:host-gateway
    command: [ "--config", "/app/config.yaml", "--port", "4000", "--num_workers", "8" ]

  nchc_postgres:
    container_name: nchc_postgres
    image: postgres:13.2-alpine
    ports:
      - ${nchc_postgres}:5432
    volumes:
      - ./storage/postgres:/var/lib/postgresql/data
    restart: always
    networks:
      - nchc    
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data
 
  nchc_pgadmin4:
    container_name: nchc_pgadmin4
    image: dpage/pgadmin4:latest
    pull_policy: always    
    ports:
      - ${nchc_pgadmin4}:5080
    volumes:
      - ./storage/pgadmin:/var/lib/pgadmin
    restart: always
    networks:
      - nchc
    depends_on:
      - nchc_postgres       
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
      PGADMIN_LISTEN_PORT: 5080
    extra_hosts:
      - host.docker.internal:host-gateway
      
  nchc_php:
    container_name: nchc_php
    image: php:8.0-fpm
    pull_policy: always    
    ports:
      - ${nchc_php}:9000
    volumes:
      - ./website:/var/www/html      
    restart: always
    networks:
      - nchc     
    extra_hosts:
      - host.docker.internal:host-gateway
      
  nchc_nginx:
    container_name: nchc_nginx
    image: nginx
    ports:
      -  ${nchc_nginx_443}:443
    volumes:
      - ./nginx/biobank_ssl:/ssl
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf 
      - ./nginx/openwebui.conf:/etc/nginx/conf.d/openwebui.conf 
      - ./nginx/anythingllm.conf:/etc/nginx/conf.d/anythingllm.conf
      - ./nginx/litellm.conf:/etc/nginx/conf.d/litellm.conf
      - ./nginx/pgadmin4.conf:/etc/nginx/conf.d/pgadmin4.conf
      - ./nginx/factory.conf:/etc/nginx/conf.d/factory.conf
      - ./nginx/llmbook.conf:/etc/nginx/conf.d/llmbook.conf
      - ./nginx/mergekit.conf:/etc/nginx/conf.d/mergekit.conf         
      - ./website:/var/www/html      
    restart: always
    networks:
        - nchc
    depends_on:
      - nchc_openwebui         
    extra_hosts:
      - host.docker.internal:host-gateway
